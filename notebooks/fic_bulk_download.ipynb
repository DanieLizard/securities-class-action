{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bulk download fic pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import requests\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import logging\n",
    "from multiprocessing.pool import ThreadPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/yuchen.zhang/Documents/Projects/Class_Action/class-action-git/src'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuchen.zhang/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/yuchen.zhang/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:8767: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n",
      "/Users/yuchen.zhang/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5254"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load input data and clean\n",
    "scraped_data = pd.read_csv(\"../../data/data_from_scrapy.csv\")\n",
    "scraped_fic = scraped_data[scraped_data['fic_summary_table'].notna()]\n",
    "scraped_fic[\"docket\"][scraped_fic[\"docket\"].isna()] = \"na\"\n",
    "scraped_fic[\"court\"][scraped_fic[\"court\"].isna()] = \"na\"\n",
    "len(scraped_fic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Unique ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuchen.zhang/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/yuchen.zhang/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/yuchen.zhang/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Unique Stanford Id and check if unique\n",
    "scraped_fic['stfid'] = scraped_fic.apply(lambda row: row.url[row.url.find(\"id=\")+len(\"id=\"):], axis = 1)\n",
    "print(len(scraped_fic['stfid'].unique()) == len(scraped_fic))\n",
    "\n",
    "# Create ids\n",
    "scraped_fic[\"cd\"] = scraped_fic[\"court\"] + \"_\" + scraped_fic[\"docket\"]\n",
    "scraped_fic[\"id\"] = scraped_fic[\"stfid\"] + \"_\" + scraped_fic[\"cd\"]\n",
    "\n",
    "# Output intermed data with unique id\n",
    "scraped_fic.to_csv(\"../../data/data_fic_id.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_brief</th>\n",
       "      <th>case_name</th>\n",
       "      <th>case_status</th>\n",
       "      <th>class_period_end</th>\n",
       "      <th>class_period_start</th>\n",
       "      <th>company_market</th>\n",
       "      <th>court</th>\n",
       "      <th>date_filed</th>\n",
       "      <th>date_of_last_review</th>\n",
       "      <th>docket</th>\n",
       "      <th>...</th>\n",
       "      <th>industry</th>\n",
       "      <th>judge</th>\n",
       "      <th>market_status</th>\n",
       "      <th>plaintiffs</th>\n",
       "      <th>sector</th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>url</th>\n",
       "      <th>stfid</th>\n",
       "      <th>cd</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>According to the Complaint, Wirecard is a tech...</td>\n",
       "      <td>Wirecard AG Securities Litigation</td>\n",
       "      <td>ONGOING</td>\n",
       "      <td>6/24/20</td>\n",
       "      <td>8/17/15</td>\n",
       "      <td>OTC-BB</td>\n",
       "      <td>E.D. Pennsylvania</td>\n",
       "      <td>7/7/20</td>\n",
       "      <td>7/8/20</td>\n",
       "      <td>20-CV-03326</td>\n",
       "      <td>...</td>\n",
       "      <td>Software &amp; Programming</td>\n",
       "      <td>Hon. ANITA B. BRODY</td>\n",
       "      <td>Public (Listed)</td>\n",
       "      <td>The Rosen Law Firm, P.A. (Jenkintown)</td>\n",
       "      <td>Technology</td>\n",
       "      <td>WCAGY</td>\n",
       "      <td>http://securities.stanford.edu/filings-case.ht...</td>\n",
       "      <td>107457</td>\n",
       "      <td>E.D. Pennsylvania_20-CV-03326</td>\n",
       "      <td>107457_E.D. Pennsylvania_20-CV-03326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>According to the Complaint, Finjan Holdings, I...</td>\n",
       "      <td>Finjan Holdings, Inc. Securities Litigation</td>\n",
       "      <td>ONGOING</td>\n",
       "      <td>6/29/20</td>\n",
       "      <td>6/10/20</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>N.D. California</td>\n",
       "      <td>6/29/20</td>\n",
       "      <td>6/30/20</td>\n",
       "      <td>20-CV-04289</td>\n",
       "      <td>...</td>\n",
       "      <td>Software &amp; Programming</td>\n",
       "      <td>Hon. Edward M. Chen</td>\n",
       "      <td>Public (Listed)</td>\n",
       "      <td>Brodsky &amp; Smith, LLC  (California)</td>\n",
       "      <td>Technology</td>\n",
       "      <td>FNJN</td>\n",
       "      <td>http://securities.stanford.edu/filings-case.ht...</td>\n",
       "      <td>107453</td>\n",
       "      <td>N.D. California_20-CV-04289</td>\n",
       "      <td>107453_N.D. California_20-CV-04289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          case_brief  \\\n",
       "0  According to the Complaint, Wirecard is a tech...   \n",
       "1  According to the Complaint, Finjan Holdings, I...   \n",
       "\n",
       "                                     case_name case_status class_period_end  \\\n",
       "0            Wirecard AG Securities Litigation     ONGOING          6/24/20   \n",
       "1  Finjan Holdings, Inc. Securities Litigation     ONGOING          6/29/20   \n",
       "\n",
       "  class_period_start company_market              court date_filed  \\\n",
       "0            8/17/15         OTC-BB  E.D. Pennsylvania     7/7/20   \n",
       "1            6/10/20         NASDAQ    N.D. California    6/29/20   \n",
       "\n",
       "  date_of_last_review       docket  ...                industry  \\\n",
       "0              7/8/20  20-CV-03326  ...  Software & Programming   \n",
       "1             6/30/20  20-CV-04289  ...  Software & Programming   \n",
       "\n",
       "                 judge    market_status  \\\n",
       "0  Hon. ANITA B. BRODY  Public (Listed)   \n",
       "1  Hon. Edward M. Chen  Public (Listed)   \n",
       "\n",
       "                              plaintiffs      sector ticker_symbol  \\\n",
       "0  The Rosen Law Firm, P.A. (Jenkintown)  Technology         WCAGY   \n",
       "1     Brodsky & Smith, LLC  (California)  Technology          FNJN   \n",
       "\n",
       "                                                 url   stfid  \\\n",
       "0  http://securities.stanford.edu/filings-case.ht...  107457   \n",
       "1  http://securities.stanford.edu/filings-case.ht...  107453   \n",
       "\n",
       "                              cd                                    id  \n",
       "0  E.D. Pennsylvania_20-CV-03326  107457_E.D. Pennsylvania_20-CV-03326  \n",
       "1    N.D. California_20-CV-04289    107453_N.D. California_20-CV-04289  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraped_fic.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>Document Title</th>\n",
       "      <th>Filing Date</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Complaint - Class Action</td>\n",
       "      <td>07/07/2020</td>\n",
       "      <td>http://securities.stanford.edu/filings-documen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>U.S. District Court Civil Docket</td>\n",
       "      <td>07/08/2020</td>\n",
       "      <td>http://securities.stanford.edu/filings-documen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No                    Document Title Filing Date  \\\n",
       "0   1          Complaint - Class Action  07/07/2020   \n",
       "1   2  U.S. District Court Civil Docket  07/08/2020   \n",
       "\n",
       "                                                link  \n",
       "0  http://securities.stanford.edu/filings-documen...  \n",
       "1  http://securities.stanford.edu/filings-documen...  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_json(scraped_fic[\"fic_summary_table\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start Downloading!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Output Folder location\n",
    "output_folder = \"/Volumes/yz-drive/class-action-filings-all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download a pdf from a link\n",
    "def url_response(url):\n",
    "    path, url = url\n",
    "    r = requests.get(url, stream = True)\n",
    "    \n",
    "    with open(output_folder + \"/\" + path,\"wb\") as pdf: \n",
    "        for chunk in r.iter_content(chunk_size=1024): \n",
    "\n",
    "            # writing one chunk at a time to pdf file \n",
    "            if chunk: \n",
    "                 pdf.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to bulk download\n",
    "#filingsDic = {}\n",
    "filingsDicAll = {}\n",
    "def downloadAll(data, dic, option=\"all\"):\n",
    "    \n",
    "    #loop through data (scraped_fic)\n",
    "    for x,y in data.iterrows():\n",
    "        #save subtable\n",
    "        table = pd.read_json(data[\"fic_summary_table\"][x])\n",
    "        print(x)\n",
    "        \n",
    "        #save unique identifier  \n",
    "        identifier = data[\"id\"][x]\n",
    "        \n",
    "        #loop through each filing in fic_summary_table\n",
    "        for i, j in table.iterrows():\n",
    "            \n",
    "            #save title and date to be parts of the dictionary and file name\n",
    "            if option == \"all\":\n",
    "                no = str(table[\"No\"][i])\n",
    "            else:\n",
    "                no = \"\"\n",
    "            title = table[\"Document Title\"][i][0:150].replace(\"/\",\"\")\n",
    "            date = table[\"Filing Date\"][i].replace(\"/\",\"\")\n",
    "            filename = identifier + \"_\" + no + title + \"_\" + date + \".pdf\"\n",
    "            print(filename)\n",
    "            \n",
    "            #duplicates management\n",
    "            ##create new key only when identifer is not a key already\n",
    "            if identifier not in dic:\n",
    "                dic[identifier] = [filename]\n",
    "            ##else only append when file name is not the value of the identifier\n",
    "            elif filename not in dic[identifier]:\n",
    "                dic[identifier].append(filename)\n",
    "            \n",
    "            url_response([filename, table[\"link\"][i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already downloaded: 5254 out of 5254\n"
     ]
    }
   ],
   "source": [
    "# Track the processing of downloading\n",
    "print(\"Already downloaded: \" + str(len(filingsDicAll.keys())) + \" out of \" + str(len(scraped_fic)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all the files!\n",
    "#downloadAll(scraped_fic,filingsDicAll, option = \"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if All files are downloaded correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16826"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count How Many documents are there\n",
    "l = []\n",
    "for x in filingsDicAll:\n",
    "    l.extend(filingsDicAll[x])\n",
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding duplicates with same id, title and date\n",
    "nodup = [] \n",
    "dup = []\n",
    "for x,y in scraped_fic.iterrows():\n",
    "    #save subtable\n",
    "    table = pd.read_json(scraped_fic[\"fic_summary_table\"][x])\n",
    "    identifier = scraped_fic[\"id\"][x]\n",
    "    \n",
    "    for i, j in table.iterrows():\n",
    "        title = table[\"Document Title\"][i].replace(\"/\",\"\")\n",
    "        date = table[\"Filing Date\"][i].replace(\"/\",\"\")\n",
    "        filename = identifier + \"_\" + title + \"_\" + date + \".pdf\"\n",
    "        \n",
    "        if filename not in nodup:\n",
    "            nodup.append(filename)\n",
    "        else:\n",
    "            dup.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 16738)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dup), len(nodup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(dup).to_csv(\"../../data/duplist.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output saved dictionary for tacking purpuses later\n",
    "with open('../../data/filingsDicAllIndent4', 'w') as json_file:\n",
    "    json.dump(filingsDicAll, json_file, indent = 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
