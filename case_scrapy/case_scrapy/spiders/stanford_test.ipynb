{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from selenium import webdriver\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "#from case_scrapy.items import case_Items\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from scrapy import Selector\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "import requests\n",
    "import lxml.html as lh\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromedriver_path = \"/Users/yuchen.zhang/Downloads/Installations/Chromedriver\"\n",
    "driver = webdriver.Chrome(executable_path = chromedriver_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_links = []\n",
    "i = 1\n",
    "first_page_html = requests.get(\"http://securities.stanford.edu/filings.html?page=1\").text\n",
    "next_page_html = requests.get(\"http://securities.stanford.edu/filings.html?page=\" + str(i+1)).text\n",
    "\n",
    "while first_page_html != next_page_html:\n",
    "    try:\n",
    "        driver.get(\"http://securities.stanford.edu/filings.html?page=\" + str(i))\n",
    "        sel_case = Selector(text=driver.page_source)\n",
    "        case_links_raw = sel_case.css('tr:nth-child(n)::attr(onclick)').getall()\n",
    "        case_links.append(case_links_raw)\n",
    "        \n",
    "        i += 1\n",
    "        next_page_html = requests.get(\"http://securities.stanford.edu/filings.html?page=\" + str(i)).text\n",
    "    except: break\n",
    "\n",
    "total_pages = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the links to actual links\n",
    "case_links_clean = []\n",
    "for i in range(0, len(case_links)):\n",
    "    for j in range(0, len(case_links[i])):\n",
    "        case_links_clean.append(\"http://securities.stanford.edu/\" + case_links[i][j].replace(\"window.location=\",\"\").replace(\"'\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(case_links_clean).to_excel(\"case_links_all.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape a whole table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"http://securities.stanford.edu/filings.html?page=1\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Securities Class Action Clearinghouse: Filings Database\n"
     ]
    }
   ],
   "source": [
    "print(soup.title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Filing Name', 'Filing Date', 'District Court', 'Exchange', 'Ticker']\n"
     ]
    }
   ],
   "source": [
    "# Get headers of the table\n",
    "case_table = soup.find(\"table\", attrs={\"class\": \"table table-bordered table-striped table-hover\"})\n",
    "table_header = soup.find('thead')\n",
    "header = table_header.find_all('th')\n",
    "header = [x.text.strip() for x in header]\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get table of the body, saving element row by row\n",
    "table_body = soup.find('tbody')\n",
    "rows = table_body.find_all('tr')\n",
    "table_list = []\n",
    "for row in rows:\n",
    "    cols=row.find_all('td')\n",
    "    cols=[x.text.strip() for x in cols]\n",
    "    table_list.append(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the complete table\n",
    "summary_table = pd.DataFrame(table_list)\n",
    "summary_table.columns = header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a function \n",
    "def get_summary_table(url):\n",
    "    # Get page\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    # Get headers of the table\n",
    "    case_table = soup.find(\"table\", attrs={\"class\": \"table table-bordered table-striped table-hover\"})\n",
    "    table_header = soup.find('thead')\n",
    "    header = table_header.find_all('th')\n",
    "    header = [x.text.strip() for x in header]\n",
    "    \n",
    "    # Get table of the body, saving element row by row\n",
    "    table_body = soup.find('tbody')\n",
    "    rows = table_body.find_all('tr')\n",
    "    table_list = []\n",
    "    for row in rows:\n",
    "        cols=row.find_all('td')\n",
    "        cols=[x.text.strip() for x in cols]\n",
    "        table_list.append(cols)\n",
    "        \n",
    "    # Save the complete table\n",
    "    summary_table = pd.DataFrame(table_list)\n",
    "    summary_table.columns = header\n",
    "    \n",
    "    return summary_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_all = pd.DataFrame()\n",
    "for i in range(1, total_pages):\n",
    "    table_all = table_all.append(get_summary_table(\"http://securities.stanford.edu/filings.html?page=\" + str(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(table_all).to_excel(\"summary_table_all.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape each page"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
